{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb05ab1-67cd-45d7-9cb8-2e5664927865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed1f96b-3fcd-4008-963f-f12f73eac541",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312212f7-13fa-49e2-ac49-54f56c69d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link_page_to_download(\n",
    "    sprzedaz: str = 'sprzedaz', \n",
    "    apartament_type: str  = 'mieszkanie', \n",
    "    region: str  = 'cala-polska',\n",
    "    price_min: int = None,\n",
    "    price_max: int = None,\n",
    "    limit: str ='36',\n",
    "    page_counter = 1\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to extract all ads from a given page from OtoDom webservice\n",
    "    \n",
    "    Args:\n",
    "        sprzedaz (str): define if it should be: sprzedaz / wynajem\n",
    "        apartament_type: type of looked apartament. Possible types: miszkanie/kawalerka/dom/inwestycja/pokoj/dzialka/lokal/haleimagazyny/garaz\n",
    "        region: cala-polska or one from voivodeship:\n",
    "            dolnoslaskie\n",
    "            kujawsko--pomorskie\n",
    "            lodzkie\n",
    "            lubelskie\n",
    "            lubuskie\n",
    "            malopolskie\n",
    "            mazowieckie\n",
    "            opolskie\n",
    "            podkarpackie\n",
    "            podlaskie\n",
    "            pomorskie\n",
    "            slaskie\n",
    "            swietokrzyskie\n",
    "            warminsko--mazurskie\n",
    "            wielkopolskie\n",
    "            zachodniopomorskie\n",
    "        price_min (int): price min of looked apartament Default = None,\n",
    "        price_max(int) = price max of looked apartament. Default = None,\n",
    "        limit limit of ads on one page possible: 24, 36 48, 72\n",
    "        page_counter: define a page number\n",
    "    Returns:\n",
    "        page_url (str): url from Oto Dom service for downloading ads details\n",
    "    \"\"\"\n",
    "    \n",
    "    main_page = 'https://www.otodom.pl/pl/wyniki'\n",
    "    sprzedaz = sprzedaz\n",
    "    apartament_type = apartament_type\n",
    "    region = region\n",
    "    limit = limit\n",
    "    price_min = price_min\n",
    "    price_max = price_max\n",
    "    last_part_if_url = f'&ownerTypeSingleSelect=ALL&priceMin={price_min}&priceMax={price_max}&by=DEFAULT&direction=DESC&viewType=listing&page={page_counter}'\n",
    "    \n",
    "    page_url = f'{main_page}/{sprzedaz}/{apartament_type}/{region}?limit={limit}{last_part_if_url}'\n",
    "    \n",
    "    return page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c73c85-d4b2-4818-97d6-f1d8b0f20fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_page_to_extract(page_url: str):\n",
    "    \"\"\"\n",
    "    Function to extract all ads from a given page from OtoDom webservice\n",
    "    Args:\n",
    "        page_url (str): link to the OtoDom page\n",
    "    \n",
    "    Returns:\n",
    "        soup (bs4.BeautifulSoup): bs4.BeautifulSoup object for future downloading data\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    page = requests.get(page_url)\n",
    "    print(page)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdae812-9dc4-4b0c-8d44-e3f63c75c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_ulrs(soup) -> list:\n",
    "    \"\"\"\n",
    "    Function to extract ftom Oto Dom page links to download data from particular ads\n",
    "    \n",
    "    Args:\n",
    "        soup (bs4.BeautifulSoup): bs4.BeautifulSoup object\n",
    "    \n",
    "    Returns:\n",
    "        list: List of linkt to the ads from given page\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_url = []\n",
    "    for a in soup.find_all('a', {\"class\": \"css-lsw81o e1dfeild2\"}, href=True):\n",
    "        one_url = a['href']\n",
    "        list_of_url.append(one_url)\n",
    "        \n",
    "    return list_of_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aeba56d-1034-403f-810f-b8071fc9b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_olx_data(list_of_url: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to extrat ads details about homes & flat in otodom website\n",
    "    \n",
    "    Args:\n",
    "        list_of_url (list): List of urls to extract data\n",
    "    \n",
    "    Returns:\n",
    "        pdDataFrame: Data Frame with details about ads from given links\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    full_df_ads_details = []\n",
    "\n",
    "    for index, one_url in enumerate(list_of_url[1]):\n",
    "\n",
    "        one_add_page = []\n",
    "        page_one_add = []\n",
    "        soup_one_add = []\n",
    "        json_data = []\n",
    "        add_details_df = pd.DataFrame()\n",
    "        characteristics_df = pd.DataFrame()\n",
    "        deeper_characteristic_df = pd.DataFrame()\n",
    "        coordinate_df = pd.DataFrame()\n",
    "        addres_df = pd.DataFrame()\n",
    "        output_ond_add_details = pd.DataFrame()\n",
    "\n",
    "        one_add_page = f'https://www.otodom.pl{one_url}'\n",
    "\n",
    "        page_one_add = requests.get(one_add_page, timeout=2)\n",
    "        \n",
    "        print(index, one_add_page, ':', page_one_add)\n",
    "        \n",
    "        soup_one_add = BeautifulSoup(page_one_add.content, 'html.parser')\n",
    "\n",
    "        soup_one_add.find_all(\"div\", {\"class\": \"css-m97llu e16xl7020\"})\n",
    "        json_data = json.loads(soup_one_add.find('script', type='application/json').text)\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"lang\"] = pd.json_normalize(json_data['props']['pageProps'])['lang']\n",
    "        except KeyError:\n",
    "            add_details_df[\"lang\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"ad_id\"] = pd.json_normalize(json_data['props']['pageProps'])['id']\n",
    "        except KeyError:\n",
    "            add_details_df[\"ad_id\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"url\"] = pd.json_normalize(json_data['props']['pageProps'])['relativeUrl']\n",
    "        except KeyError:\n",
    "            add_details_df[\"url\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"ad_id2\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['id']\n",
    "        except KeyError:\n",
    "            add_details_df[\"ad_id2\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"market\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['market']\n",
    "        except KeyError:\n",
    "            add_details_df[\"market\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"publicId\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['publicId']\n",
    "        except KeyError:\n",
    "            add_details_df[\"publicId\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"slug\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['slug']\n",
    "        except KeyError:\n",
    "            add_details_df[\"slug\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"advertiserType\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['advertiserType']\n",
    "        except KeyError:\n",
    "            add_details_df[\"advertiserType\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"createdAt\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['createdAt']\n",
    "        except KeyError:\n",
    "            add_details_df[\"createdAt\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"modifiedAt\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['modifiedAt']\n",
    "        except KeyError:\n",
    "            add_details_df[\"modifiedAt\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"description\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['description']\n",
    "        except KeyError:\n",
    "            add_details_df[\"description\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"title\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['title']\n",
    "        except KeyError:\n",
    "            add_details_df[\"title\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"full_url\"] = pd.json_normalize(json_data['props']['pageProps']['ad'])['url']\n",
    "        except KeyError:\n",
    "            add_details_df[\"full_url\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"price\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'price'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"price\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"m\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'm'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"m\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"price_per_m\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'price_per_m'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"price_per_m\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"rooms_num\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'rooms_num'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"rooms_num\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"floor_no\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"label == 'Piętro'\")['localizedValue']\n",
    "        except KeyError:\n",
    "            add_details_df[\"floor_no\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"heating\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'heating'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"heating\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"building_ownership\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['characteristics']).query(\"key == 'building_ownership'\")['value']\n",
    "        except KeyError:\n",
    "            add_details_df[\"building_ownership\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"city\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['target'])['City']\n",
    "        except KeyError:\n",
    "            add_details_df[\"city\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"City_id\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['target'])['City_id']\n",
    "        except KeyError:\n",
    "            add_details_df[\"City_id\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"Country\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['target'])['Country']\n",
    "        except KeyError:\n",
    "            add_details_df[\"Country\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"MarketType\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['target'])['MarketType']\n",
    "        except KeyError:\n",
    "            add_details_df[\"MarketType\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"PriceRange\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['target'])['PriceRange']\n",
    "        except KeyError:\n",
    "            add_details_df[\"PriceRange\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"latitude\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['location']['coordinates'])['latitude']\n",
    "        except KeyError:\n",
    "            add_details_df[\"latitude\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"longitude\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['location']['coordinates'])['longitude']\n",
    "        except KeyError:\n",
    "            add_details_df[\"longitude\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"district_name\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['location']['address'])['district.code']\n",
    "        except KeyError:\n",
    "            add_details_df[\"district_name\"] = 'None'\n",
    "\n",
    "        try:\n",
    "            add_details_df[\"district.id\"] = pd.json_normalize(json_data['props']['pageProps']['ad']['location']['address'])['district.id']\n",
    "        except KeyError:\n",
    "            add_details_df[\"district.id\"] = 'None'\n",
    "\n",
    "        full_df_ads_details.append(add_details_df)\n",
    "        \n",
    "    full_df_ads_details = pd.concat(full_df_ads_details, axis=0)    \n",
    "    return full_df_ads_details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3e8f56-9e46-4645-b1f0-e49aa2d3dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "    sprzedaz: str = 'sprzedaz', \n",
    "    apartament_type: str  = 'mieszkanie',\n",
    "    region: str = 'mazowieckie',\n",
    "    price_min:int = None,\n",
    "    price_max: int = None,\n",
    "    limit: str ='72',\n",
    "    path_to_save_batch_files: str = None,\n",
    "    path_to_save_full_files: str = None,\n",
    "    sys_sleeping: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    function for downloading data from Oto Dom Service\n",
    "    \n",
    "    Args:\n",
    "        sprzedaz (str): define if it should be: sprzedaz / wynajem\n",
    "        apartament_type: type of looked apartament. Possible types: miszkanie/kawalerka/dom/inwestycja/pokoj/dzialka/lokal/haleimagazyny/garaz\n",
    "        region: cala-polska or one from voivodeship:\n",
    "            dolnoslaskie\n",
    "            kujawsko--pomorskie\n",
    "            lodzkie\n",
    "            lubelskie\n",
    "            lubuskie\n",
    "            malopolskie\n",
    "            mazowieckie\n",
    "            opolskie\n",
    "            podkarpackie\n",
    "            podlaskie\n",
    "            pomorskie\n",
    "            slaskie\n",
    "            swietokrzyskie\n",
    "            warminsko--mazurskie\n",
    "            wielkopolskie\n",
    "            zachodniopomorskie\n",
    "        price_min (int): price min of looked apartament Default = None,\n",
    "        price_max(int) = price max of looked apartament. Default = None,\n",
    "        limit limit of ads on one page possible: 24, 36 48, 72\n",
    "        path_to_save_batch_files (str): path for saving batch files. Default is saving file in directory from scrip running\n",
    "        path_to_save_full_files (str): path for saving fill data set file. Default is saving file in directory from scrip running\n",
    "        sys_sleeping (int): System sleeping between loops. In seconds\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data Frame with data about ads from Oto Dom service\n",
    "    \"\"\"\n",
    "    \n",
    "    full_df_ads_data_details = []\n",
    "    full_ds = []\n",
    "    date_of_download = date.today()\n",
    "\n",
    "    running = True\n",
    "    page_counter = 1\n",
    "    while running:\n",
    "\n",
    "        next_link_to_download = []\n",
    "        next_soup_page = []\n",
    "        next_list_of_ads_links = []\n",
    "        next_ads_details = []\n",
    "\n",
    "        next_link_to_download = create_link_page_to_download(\n",
    "            sprzedaz = 'sprzedaz', \n",
    "            apartament_type  = 'mieszkanie',\n",
    "            region = 'mazowieckie',\n",
    "            price_min = None,\n",
    "            price_max = 150000,\n",
    "            limit ='24', \n",
    "\n",
    "            page_counter = page_counter)\n",
    "\n",
    "        print(next_link_to_download)\n",
    "\n",
    "        # step 2\n",
    "\n",
    "        next_soup_page = define_page_to_extract(page_url = next_link_to_download)\n",
    "\n",
    "        # step 3 \n",
    "\n",
    "        next_list_of_ads_links = create_list_of_ulrs(soup = next_soup_page)\n",
    "\n",
    "        # step 4\n",
    "        try:\n",
    "            next_ads_details = extract_olx_data(list_of_url = next_list_of_ads_links)\n",
    "            next_ads_details.to_csv(f'{path_to_save_batch_files}/data_part_{page_counter}_{date_of_download}.csv')\n",
    "        except ValueError:\n",
    "            running = False\n",
    "            print('No More Data = stop downloading data')\n",
    "\n",
    "        full_df_ads_data_details.append(next_ads_details)\n",
    "\n",
    "        page_counter += 1\n",
    "        time.sleep(sys_sleeping)\n",
    "\n",
    "    full_df_ads_data_details = full_df_ads_data_details[ : -1]\n",
    "    full_ds = pd.concat(full_df_ads_data_details, axis=0)\n",
    "\n",
    "    full_ds.to_csv(f'{path_to_save_full_files}/full_oto_dom_data_{date_of_download}.csv')\n",
    "    \n",
    "    return full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c2322-c236-440f-9021-c4c1dd2dd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = download_data(    \n",
    "    sprzedaz ='sprzedaz', \n",
    "    apartament_type  = 'mieszkanie',\n",
    "    region ='mazowieckie',\n",
    "    price_min = None,\n",
    "    price_max = 150000,\n",
    "    limit = '72',\n",
    "    path_to_save_batch_files = None,\n",
    "    path_to_save_full_files = None,\n",
    "    sys_sleeping = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "politechnika",
   "language": "python",
   "name": "politechnika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
